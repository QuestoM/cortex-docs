# Context Summarizer

L2/L3 LLM-based summarization for the Cortical Context Engine. L2 produces narrative summaries (10:1-20:1 compression), L3 produces structured JSON digests (50:1-100:1). Pure prompt-builder module -- no LLM calls inside.

::: corteX.engine.context_summarizer
    options:
      show_source: true
      members_order: source
